{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3da9ca1f-425d-45d8-8975-a496780d4b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting s3fs\n",
      "  Downloading s3fs-2023.12.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting aiobotocore<3.0.0,>=2.5.4 (from s3fs)\n",
      "  Downloading aiobotocore-2.9.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting fsspec==2023.12.2 (from s3fs)\n",
      "  Downloading fsspec-2023.12.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from s3fs)\n",
      "  Downloading aiohttp-3.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting botocore<1.33.14,>=1.33.2 (from aiobotocore<3.0.0,>=2.5.4->s3fs)\n",
      "  Downloading botocore-1.33.13-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting wrapt<2.0.0,>=1.10.10 (from aiobotocore<3.0.0,>=2.5.4->s3fs)\n",
      "  Downloading wrapt-1.16.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs)\n",
      "  Downloading aioitertools-0.11.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (23.1.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs)\n",
      "  Downloading multidict-6.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.4/117.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs)\n",
      "  Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs)\n",
      "  Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from botocore<1.33.14,>=1.33.2->aiobotocore<3.0.0,>=2.5.4->s3fs)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.11/site-packages (from botocore<1.33.14,>=1.33.2->aiobotocore<3.0.0,>=2.5.4->s3fs) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /opt/conda/lib/python3.11/site-packages (from botocore<1.33.14,>=1.33.2->aiobotocore<3.0.0,>=2.5.4->s3fs) (2.0.7)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (3.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.33.14,>=1.33.2->aiobotocore<3.0.0,>=2.5.4->s3fs) (1.16.0)\n",
      "Downloading s3fs-2023.12.2-py3-none-any.whl (28 kB)\n",
      "Downloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.0/169.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiobotocore-2.9.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.33.13-py3-none-any.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.3/272.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.16.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.7/80.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (328 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.1/328.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: wrapt, multidict, jmespath, fsspec, frozenlist, aioitertools, yarl, botocore, aiosignal, aiohttp, aiobotocore, s3fs\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.9.2\n",
      "    Uninstalling fsspec-2023.9.2:\n",
      "      Successfully uninstalled fsspec-2023.9.2\n",
      "Successfully installed aiobotocore-2.9.0 aiohttp-3.9.1 aioitertools-0.11.0 aiosignal-1.3.1 botocore-1.33.13 frozenlist-1.4.1 fsspec-2023.12.2 jmespath-1.0.1 multidict-6.0.4 s3fs-2023.12.2 wrapt-1.16.0 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "047272e5-b8ba-4b98-afa2-19dbfd882e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import s3fs\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Row\n",
    "import pyspark.sql.types as T\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c676982-a73a-42fe-b44f-48cfc27472e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define environment variables\n",
    "os.environ[\"MINIO_KEY\"] = \"minio\"\n",
    "os.environ[\"MINIO_SECRET\"] = \"minio123\"\n",
    "os.environ[\"MINIO_ENDPOINT\"] = \"http://minio1:9000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34e0a4d0-cc68-4f60-a2bc-39db2b5acf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"country_data_analysis\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.11.1026,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.0.0\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", os.environ[\"MINIO_ENDPOINT\"]) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", os.environ[\"MINIO_KEY\"]) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", os.environ[\"MINIO_SECRET\"]) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afe76fd5-c844-4091-864a-49965ee05676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version 2.12.18\n"
     ]
    }
   ],
   "source": [
    "scala_version = spark.sparkContext._jvm.scala.util.Properties.versionString()\n",
    "print(scala_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b4c00cf-9de0-4873-9055-50bcf4d7a71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+-------------+\n",
      "|   name|age|         city|\n",
      "+-------+---+-------------+\n",
      "|  Alice| 25|     New York|\n",
      "|    Bob| 30|San Francisco|\n",
      "|Charlie| 35|  Los Angeles|\n",
      "+-------+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "data = [\n",
    "    Row(name=\"Alice\", age=25, city=\"New York\"),\n",
    "    Row(name=\"Bob\", age=30, city=\"San Francisco\"),\n",
    "    Row(name=\"Charlie\", age=35, city=\"Los Angeles\")\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fd54119-ef51-4b55-9188-94969ff467eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"avro\").save(\"s3a://mybucket/avro_test.avro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5a4c1f9-d8bc-4bd1-8c20-668f0f7f767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.orc(\"s3a://mybucket/orc_test.orc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd3d3c65-9c7d-41cd-9c08-65283d300dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"delta\").save(\"s3a://mybucket/delta_test.delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "201ef522-2de1-4781-b6e8-8298ce71d92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyspark.sql.types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9f7fbb3-ca2e-4f6a-be8e-ca60b47417ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows\n",
    "num_rows = 10000000\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.range(0, num_rows)\n",
    "\n",
    "# Add columns\n",
    "for i in range(1, 10):  # Since we already have one column\n",
    "    if i % 2 == 0:\n",
    "        # Integer column\n",
    "        df = df.withColumn(f\"int_col_{i}\", (F.randn() * 100).cast(T.IntegerType()))\n",
    "    else:\n",
    "        # String column\n",
    "        df = df.withColumn(f\"str_col_{i}\", (F.rand() * num_rows).cast(T.IntegerType()).cast(\"string\"))\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2b72f3c-10ab-405c-9377-69aee6731d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "|id |str_col_1|int_col_2|str_col_3|int_col_4|str_col_5|int_col_6|str_col_7|int_col_8|str_col_9|\n",
      "+---+---------+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "|0  |4830797  |93       |4007619  |-51      |6700735  |195      |9445928  |8        |129749   |\n",
      "|1  |2322908  |-107     |1688929  |-9       |3442013  |-166     |9299275  |71       |616359   |\n",
      "|2  |9361958  |77       |1420421  |-153     |6481478  |12       |5484855  |214      |8059242  |\n",
      "|3  |7139320  |140      |4121314  |32       |2932949  |168      |4717922  |-88      |3108094  |\n",
      "|4  |1137218  |63       |8184623  |108      |6391560  |-33      |3639632  |71       |7167665  |\n",
      "|5  |7218166  |-45      |164020   |-50      |2179791  |-41      |2611901  |-71      |1909397  |\n",
      "|6  |1421819  |-119     |1065251  |75       |931146   |-37      |1188891  |-99      |1614681  |\n",
      "|7  |8235943  |217      |1356612  |81       |3973052  |85       |7312485  |-52      |6400245  |\n",
      "|8  |7252996  |-289     |7249615  |1        |386575   |55       |927467   |189      |4170779  |\n",
      "|9  |7237374  |54       |9538015  |259      |3274761  |169      |4915565  |30       |8172732  |\n",
      "+---+---------+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10,truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "321fb7d4-6f49-4ce5-ad18-d7997e0046f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = false)\n",
      " |-- str_col_1: string (nullable = true)\n",
      " |-- int_col_2: integer (nullable = true)\n",
      " |-- str_col_3: string (nullable = true)\n",
      " |-- int_col_4: integer (nullable = true)\n",
      " |-- str_col_5: string (nullable = true)\n",
      " |-- int_col_6: integer (nullable = true)\n",
      " |-- str_col_7: string (nullable = true)\n",
      " |-- int_col_8: integer (nullable = true)\n",
      " |-- str_col_9: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85860495-3a25-42c8-bc71-dd2b1cf86b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.csv(\"s3a://mybucket/ten_million_parquet.csv\")\n",
    "df.write.csv(\"s3a://mybucket/ten_million_avro.csv\")\n",
    "df.write.csv(\"s3a://mybucket/ten_million_orc.csv\")\n",
    "df.write.csv(\"s3a://mybucket/ten_million_delta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d879ae1c-f42a-4800-9b06-34c85fc95dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = T.StructType([\n",
    "    T.StructField(\"id\", T.LongType(), nullable=False),\n",
    "    T.StructField(\"str_col_1\", T.StringType(), nullable=True),\n",
    "    T.StructField(\"int_col_2\", T.IntegerType(), nullable=True),\n",
    "    T.StructField(\"str_col_3\", T.StringType(), nullable=True),\n",
    "    T.StructField(\"int_col_4\", T.IntegerType(), nullable=True),\n",
    "    T.StructField(\"str_col_5\", T.StringType(), nullable=True),\n",
    "    T.StructField(\"int_col_6\", T.IntegerType(), nullable=True),\n",
    "    T.StructField(\"str_col_7\", T.StringType(), nullable=True),\n",
    "    T.StructField(\"int_col_8\", T.IntegerType(), nullable=True),\n",
    "    T.StructField(\"str_col_9\", T.StringType(), nullable=True)\n",
    "])\n",
    "\n",
    "df_csv_parquet = spark.read.format(\"csv\").option(\"header\",True).schema(schema).load(\"s3a://mybucket/ten_million_parquet.csv\")\n",
    "df_csv_avro = spark.read.format(\"csv\").option(\"header\",True).schema(schema).load(\"s3a://mybucket/ten_million_avro.csv\")\n",
    "df_csv_orc = spark.read.format(\"csv\").option(\"header\",True).schema(schema).load(\"s3a://mybucket/ten_million_orc.csv\")\n",
    "df_csv_delta = spark.read.format(\"csv\").option(\"header\",True).schema(schema).load(\"s3a://mybucket/ten_million_delta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db9214f6-3091-4e48-855d-26ccc7f3680e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- str_col_1: string (nullable = true)\n",
      " |-- int_col_2: integer (nullable = true)\n",
      " |-- str_col_3: string (nullable = true)\n",
      " |-- int_col_4: integer (nullable = true)\n",
      " |-- str_col_5: string (nullable = true)\n",
      " |-- int_col_6: integer (nullable = true)\n",
      " |-- str_col_7: string (nullable = true)\n",
      " |-- int_col_8: integer (nullable = true)\n",
      " |-- str_col_9: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd2659ce-45ac-43ea-9158-e458258e811d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to write as Parquet: 54.626307249069214 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df_csv_parquet.write.parquet(\"s3a://mybucket/ten_million_parquet2.parquet\")\n",
    "end_time = time.time()\n",
    "print(f\"Time taken to write as Parquet: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae6f9b1c-92ca-4c7c-80e6-799c630f6b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to write as Avro: 46.201910972595215 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df_csv_avro.write.format(\"avro\").save(\"s3a://mybucket/ten_million_avro2.avro\")\n",
    "end_time = time.time()\n",
    "print(f\"Time taken to write as Avro: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed9b05ca-adb0-4318-90a5-cfbc13609c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to write as ORC: 62.553457736968994 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df_csv_orc.write.orc(\"s3a://mybucket/ten_million_orc2.orc\")\n",
    "end_time = time.time()\n",
    "print(f\"Time taken to write as ORC: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5525ec80-4ba2-494c-b1fe-a7981f749fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to write as Delta Lake: 61.09932518005371 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df_csv_delta.write.format(\"delta\").save(\"s3a://mybucket/ten_million_delta2.delta\")\n",
    "end_time = time.time()\n",
    "print(f\"Time taken to write as Delta Lake: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e2d016",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet = spark.read.parquet(\"s3a://mybucket/ten_million_parquet2.parquet\")\n",
    "df_parquet.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d6d5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avro = spark.read.format(\"avro\").load(\"s3a://mybucket/ten_million_avro2.avro\")\n",
    "df_avro.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37c0b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orc = spark.read.orc(\"s3a://mybucket/ten_million_orc2.orc\")\n",
    "df_orc.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56cdb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delta = spark.read.format(\"delta\").load(\"s3a://mybucket/ten_million_delta2.delta\")\n",
    "df_delta.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17faf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "df_parquet \\\n",
    ".select(\"str_col_5\",\"str_col_7\",\"int_col_2\") \\\n",
    ".groupBy(\"str_col_5\",\"str_col_7\") \\\n",
    ".count() \\\n",
    ".orderBy(\"count\") \\\n",
    ".limit(1) \\\n",
    ".show(truncate = False)\n",
    "end_time = time.time()\n",
    "print(f\"Time taken for query: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32584db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "df_avro \\\n",
    ".select(\"str_col_5\",\"str_col_7\",\"int_col_2\") \\\n",
    ".groupBy(\"str_col_5\",\"str_col_7\") \\\n",
    ".count() \\\n",
    ".orderBy(\"count\") \\\n",
    ".limit(1) \\\n",
    ".show(truncate = False)\n",
    "end_time = time.time()\n",
    "print(f\"Time taken for query: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8a61d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "df_orc \\\n",
    ".select(\"str_col_5\",\"str_col_7\",\"int_col_2\") \\\n",
    ".groupBy(\"str_col_5\",\"str_col_7\") \\\n",
    ".count() \\\n",
    ".orderBy(\"count\") \\\n",
    ".limit(1) \\\n",
    ".show(truncate = False)\n",
    "end_time = time.time()\n",
    "print(f\"Time taken for query: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590fe655",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "df_delta \\\n",
    ".select(\"str_col_5\",\"str_col_7\",\"int_col_2\") \\\n",
    ".groupBy(\"str_col_5\",\"str_col_7\") \\\n",
    ".count() \\\n",
    ".orderBy(\"count\") \\\n",
    ".limit(1) \\\n",
    ".show(truncate = False)\n",
    "end_time = time.time()\n",
    "print(f\"Time taken for query: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c7f9778-8ed5-4a19-8249-e61a562222ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CSV: 74.4 MiB * 8 = 595.2 MiB\n",
    "ORC: 44.7 MiB * 8 = 357.6 MiB\n",
    "Parquet: 53.6 MiB * 8 = 428.8 MiB\n",
    "Avro: 60.2 MiB * 8 = 481.6 MiB\n",
    "Delta Lake: 53.6 MiB * 8 = 428.8 MiB\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67da972a-7ad0-4953-ba3b-4e8266512fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  minio:\n",
    "    image: minio/minio\n",
    "    container_name: minio1\n",
    "    ports:\n",
    "      - \"9000:9000\"\n",
    "      - \"9001:9001\"\n",
    "    volumes:\n",
    "      - /mnt/data:/data\n",
    "    environment:\n",
    "      MINIO_ROOT_USER: minio\n",
    "      MINIO_ROOT_PASSWORD: minio123\n",
    "    command: server /data --console-address \":9001\"\n",
    "\n",
    "  jupyter:\n",
    "    image: quay.io/jupyter/pyspark-notebook\n",
    "    ports:\n",
    "      - \"8888:8888\"\n",
    "      - \"4040:4040\"\n",
    "      - \"4041:4041\"\n",
    "      - \"4042:4042\"\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
